{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP4  L'optimisation par essaim de particules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'optimisation par essaims particulaires (Particle Swarm Optimization) est une méthode d'optimisation qui s’inspire du comportement collectif des oiseaux pour résoudre des problèmes d’optimisation.\n",
    "Dans l'algorithme PSO, une population de particules est initialisée aléatoirement dans l'espace de recherche.  Chaque particule possède une position qui code une solution candidate et une vitesse qui contrôle le déplacement de la particule.\n",
    "La qualité de la solution est mesurée par une fonction fitness associée au problème d'optimisation qu'on veut résoudre. \n",
    "Les particules explorent l'espace en fonction de leur direction actuelle, de leur experience personnelle (pbest position) et de leur information sociale (gbest position).\n",
    "\n",
    "Les étapes du PSO se résument comme suit :\n",
    "\n",
    "1- Initialisation: Les positions et les vitesses des particules sont initialisées de manière aléatoire dans l'espace de recherche.\n",
    "                   La position courante est aussi considérée comme pbest \n",
    "        \n",
    "2- Evaluation:     La position actuelle de chaque particule est évaluée par la fonction fitness à optimiser.\n",
    "                    soit gbest la meilleur particule de la population    \n",
    "\n",
    "3 - Pendant M iterations\n",
    "\n",
    "    a- Mise à jour de la vitesse : Les particules ajustent leur vitesse en fonction de leur vitesse actuelle, de leur \n",
    "       meilleure position personnelle pbest et de la meilleure position gbest.\n",
    "    b- Mise à jour de la position  : Les particules ajustent leur position en fonction de la position en cours et \n",
    "       de la nouvelle vitesse\n",
    "    c- Mise à jour de la meilleure position personnelle (pbest) : si la nouvelle position de la particule est meilleure \n",
    "       que sa pbest alors remplacer pbest par cette nouvelle position\n",
    "    d- Mise à jour de la meilleure position globale (gbest) \n",
    "\n",
    "4- retourner gbest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application de l'algorithme PSO pour la sélection des caractéristiques du dataset Iris\n",
    "\n",
    "Dans ce TP, nous allons utiliser l'algorithme PSO pour la sélection des caractéristiques pertinentes du dataset Iris qui maximise l'accuracy du classificateur MLP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Import libraries  pour la classification \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normaliser les données\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "iris_norm=scaler.transform(X)\n",
    "#print(iris_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_norm, y, test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with the 4 features = 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# classer iris_norm avec toutes les features\n",
    "#Building the MLP model \n",
    "mlp=MLPClassifier(solver='sgd', learning_rate_init=0.01, max_iter=10000,random_state=100)\n",
    "mlp.fit(x_train, y_train)                   \n",
    "y_hat = mlp.predict(x_test)                  \n",
    "prec = accuracy_score(y_test, y_hat)\n",
    "print(\"Accuracy with the 4 features =\",prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (105, 4)\n",
      "[(0,), (1,), (2,), (3,)]\n",
      "[(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]\n",
      "[(0, 1, 2), (0, 1, 3), (0, 2, 3), (1, 2, 3)]\n",
      "[(0, 1, 2, 3)]\n",
      "Features: (1,) - Score: 0.6222222222222222\n",
      "Features: (0,) - Score: 0.6888888888888889\n",
      "Features: (0, 1) - Score: 0.8\n",
      "Features: (0, 1, 2) - Score: 0.9555555555555556\n",
      "Features: (0, 2) - Score: 0.9555555555555556\n",
      "Features: (1, 2) - Score: 0.9555555555555556\n",
      "Features: (1, 3) - Score: 0.9555555555555556\n",
      "Features: (2,) - Score: 0.9555555555555556\n",
      "Features: (0, 1, 2, 3) - Score: 0.9777777777777777\n",
      "Features: (0, 1, 3) - Score: 0.9777777777777777\n",
      "Features: (0, 2, 3) - Score: 0.9777777777777777\n",
      "Features: (0, 3) - Score: 0.9777777777777777\n",
      "Features: (1, 2, 3) - Score: 0.9777777777777777\n",
      "Features: (2, 3) - Score: 0.9777777777777777\n",
      "Features: (3,) - Score: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# tester toutes les combinaisons possibles de features\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "from itertools import combinations\n",
    "scores = []\n",
    "\n",
    "for i in range(1,5):\n",
    "    list_combs = list(combinations(range(x_train.shape[1]), i))\n",
    "    print(list_combs)\n",
    "    # Calculer le score de classification pour chaque combinaison\n",
    "    for combi in list_combs:\n",
    "        X_subset = x_train[:, combi]  # Sélectionner uniquement les fonctionnalités de la combinaison\n",
    "        mlp=MLPClassifier(solver='sgd', learning_rate_init=0.01, max_iter=10000,random_state=100)\n",
    "        mlp.fit(X_subset, y_train)                   #Training the Model with x_train & y_train\n",
    "        y_hat = mlp.predict(x_test[:,combi])                 #Predicting the x_test \n",
    "        prec = accuracy_score(y_test, y_hat)\n",
    "        scores.append((prec, combi))\n",
    "   \n",
    "\n",
    "# Trier les scores et les combinaisons par ordre croissant de scores\n",
    "sorted_scores = sorted(scores)\n",
    "\n",
    "# Afficher les combinaisons et leurs scores de classification triés\n",
    "for score, comb in sorted_scores:\n",
    "    print(\"Features:\", comb, \"- Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametres de l'algortithme PSO\n",
    "num_particles = 30\n",
    "max_iter = 100\n",
    "w=0.5\n",
    "c1=2\n",
    "c2=2\n",
    "Vmax=-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(selected_features):\n",
    "    \n",
    "     \n",
    "   \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_particles(num_particles, num_features):\n",
    "    # Initialiser aléatoirement les positions et les vitesses\n",
    "    return  particles_position, particles_velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pbest(????):\n",
    "    # mise à jour de pbest\n",
    "     \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction sigmoïde\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_particles:\n",
    "    # mise à jour des vitesses et des positions des particules\n",
    "     \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fitness\n",
    "    # Evaluer la fonction fitness de chaque particule\n",
    "     \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_gbest\n",
    "    # mise à jour du gbest \n",
    "     \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pso\n",
    "    \n",
    "     \n",
    "    return global_best_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer l'algorithme PSO algorithm pour la feature selection\n",
    "# afficher le nombre moyen des features sélectionnées et l'accuracy moyenne de 10 run du PSO\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
